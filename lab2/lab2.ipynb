{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Rozwiązanie laboratorium 2"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "outputs": [],
   "source": [
    "from queue import PriorityQueue\n",
    "from time import perf_counter"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Funkcje konwertujące"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "outputs": [],
   "source": [
    "def string_to_int(string):\n",
    "    val = 0\n",
    "    for x in string:\n",
    "        val = val << 1 | (0 if x == '0' else 1)\n",
    "    return val\n",
    "\n",
    "\n",
    "def int_to_string(x, no_of_bits):\n",
    "    string = []\n",
    "    mask = 1 << (no_of_bits - 1)\n",
    "    for _ in range(no_of_bits):\n",
    "        string.append(\"1\" if x & mask else \"0\")\n",
    "        mask >>= 1\n",
    "    return \"\".join(string)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Wczytytywanie i odczytywanie z plików binarnych/tekstowych"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [],
   "source": [
    "def read_file_to_string(filename):\n",
    "    with open(filename, \"r\", encoding=\"UTF-8\") as f:\n",
    "        data = f.read()\n",
    "    return data\n",
    "\n",
    "\n",
    "def read_binary_file_to_string(filename):\n",
    "    with open(filename, 'rb') as f:\n",
    "        bit_data = f.read()\n",
    "\n",
    "    data = []\n",
    "    for bit in bit_data[:-2]:\n",
    "        data.append(int_to_string(bit, 8))\n",
    "    last = \"\"\n",
    "    mask = 1 << 7\n",
    "    if bit_data[-1]:\n",
    "        for j in range(bit_data[-1]):\n",
    "            last += \"1\" if mask & bit_data[-2] else \"0\"\n",
    "            mask >>= 1\n",
    "    else:\n",
    "        for j in range(8):\n",
    "            last += \"1\" if mask & bit_data[-2] else \"0\"\n",
    "            mask >>= 1\n",
    "    data.append(last)\n",
    "    return \"\".join(data)\n",
    "\n",
    "\n",
    "def write_string_to_binary_file(filename, text):\n",
    "    b = bytearray()\n",
    "    for i in range(0, len(text), 8):\n",
    "        b.append(string_to_int(text[i:i+8]))\n",
    "\n",
    "    with open(filename, 'wb') as f:\n",
    "        f.write(b)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [],
   "source": [
    "def add_last_bits(text):\n",
    "    padding_length = len(text) % 8\n",
    "    text += \"0\" * ((8 - padding_length)%8)\n",
    "    text += int_to_string(padding_length, 8)\n",
    "    return text"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Statyczne drzewo Huffmana\n",
    "\n",
    "Przy kompresowaniu pliku początkowo zakodowane litery zapisuje jako zera i jedynki (znaki ascii). Też do takiej formy\n",
    "zapisuje wczytywany plik. Dopiero potem znaki odpowiednio konweruje na liczby i zapisuje do plików. Używanie stringów było jednak najwygodniejsze."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [],
   "source": [
    "class StaticNode:\n",
    "    def __init__(self, character=None):\n",
    "        self.character = character\n",
    "        self.left = None\n",
    "        self.right = None\n",
    "\n",
    "class StaticHuffman:\n",
    "    def __init__(self):\n",
    "        self.tree_root = None\n",
    "        self.frequency_dict = {}\n",
    "        self.code_dict = {}\n",
    "\n",
    "    def build_frequency_dict(self, data):\n",
    "        for c in data:\n",
    "            if c not in self.frequency_dict:\n",
    "                self.frequency_dict[c] = 1\n",
    "            else:\n",
    "                self.frequency_dict[c] += 1\n",
    "\n",
    "    def build_tree(self):\n",
    "        pq = PriorityQueue()\n",
    "        for c in self.frequency_dict:\n",
    "            pq.put((self.frequency_dict[c], c, StaticNode(c)))\n",
    "\n",
    "        while True:\n",
    "            freq1, str1, node1 = pq.get()\n",
    "            if pq.empty():\n",
    "                self.tree_root = node1\n",
    "                return\n",
    "            freq2, str2, node2 = pq.get()\n",
    "            new_node = StaticNode()\n",
    "            new_node.left = node1\n",
    "            new_node.right = node2\n",
    "            pq.put((freq1 + freq2, str1 + str2, new_node))\n",
    "\n",
    "    def code_characters(self):\n",
    "        def traverse_tree(node, code=\"\"):\n",
    "            if node.character is not None:\n",
    "                self.code_dict[node.character] = code\n",
    "            else:\n",
    "                traverse_tree(node.left, code + '0')\n",
    "                traverse_tree(node.right, code + '1')\n",
    "\n",
    "        traverse_tree(self.tree_root, code=\"\")\n",
    "\n",
    "    def encode_text(self, text):\n",
    "        self.build_frequency_dict(text)\n",
    "        self.build_tree()\n",
    "        self.code_characters()\n",
    "        encoded = []\n",
    "        for c in text:\n",
    "            encoded.append(self.code_dict[c])\n",
    "        return add_last_bits(\"\".join(encoded))\n",
    "\n",
    "    def decode_text(self, text):\n",
    "        ind = 0\n",
    "        decoded = []\n",
    "        while ind < len(text):\n",
    "            ptr = self.tree_root\n",
    "            while ptr.character is None:\n",
    "                ptr = ptr.left if text[ind] == '0' else ptr.right\n",
    "                ind += 1\n",
    "            decoded.append(ptr.character)\n",
    "        return \"\".join(decoded)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Dynamiczne drzewo Huffmana\n",
    "\n",
    "Podobnie jak w statycznym drzewie Huffmana w samym programie używam stringów.\n",
    "Moja implementacja bazuje na algorytmie FGK(Faller-Gallager-Knuth). Otrzymana struktura nie jest najszybsza.\n",
    "Można by to poprawić, gdyby struktury self.node_weights i self.leaf_weights ( atrybuty klasy AdaptiveHuffman ), byłyby listami posortowanych\n",
    "zbiorór (np. drzew AVL), a nie zwykłych zbiorów.\n",
    "Ponadto, jako że przy dekodowaniu w dynamicznym drzewie Huffmana drzewo jest tworzone na nowo i nie wiadomo jakie litery mogą się pojawić, w momencie, gdy\n",
    "po raz pierwszy napotykamy musimy ją zapisać w kodzie \"normalnie\". W pythonie jest dostępna funkcja ord(), która dla znaku zwraca liczbę z kodu ascii\n",
    "Działa ona jednak dla każdej znaku z UTF-8 ( większość plików chociażby z gutenberg.ord jest w takim formacie). Niektóre jednak znaki nie mieszczą się na jednym bajcie, lecz dopiero na dwóch. Dlatego przy kodowaniu nowo napotkanego znaku używałem zawsze 16 bitów. Dany znak jest tak zapisywany tylko raz, więc nie ma to znaczenia dla plików, które są większe niż kilka kilobajtów, lecz dla małych plików, w których jest dużo różnych znaków współczynnik kompresji może być bardzo niski."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [],
   "source": [
    "class AdaptiveNode:\n",
    "    def __init__(self, index, weight, character, external):\n",
    "        self.index = index\n",
    "        self.weight = weight\n",
    "        self.character = character\n",
    "        self.external = external\n",
    "        self.left = None\n",
    "        self.right = None\n",
    "        self.parent = None\n",
    "\n",
    "\n",
    "def interchange(node, change):\n",
    "    if change != node:\n",
    "        change.index, node.index = node.index, change.index\n",
    "        parent_change, parent_node = change.parent, node.parent\n",
    "        if parent_change.left == change:\n",
    "            if parent_node.left == node:\n",
    "                parent_change.left, parent_node.left = node, change\n",
    "            else:\n",
    "                parent_change.left, parent_node.right = node, change\n",
    "        else:\n",
    "            if parent_node.left == node:\n",
    "                parent_change.right, parent_node.left = node, change\n",
    "            else:\n",
    "                parent_change.right, parent_node.right = node, change\n",
    "        node.parent, change.parent = parent_change, parent_node\n",
    "\n",
    "\n",
    "def update_weight(node, node_dict):\n",
    "    node_dict[node.weight].remove(node)\n",
    "    if node.weight + 1 >= len(node_dict):\n",
    "        node_dict.append(set())\n",
    "    node_dict[node.weight + 1].add(node)\n",
    "\n",
    "\n",
    "class AdaptiveHuffman:\n",
    "    def __init__(self):\n",
    "        self.root = AdaptiveNode(1000, 0, \"NYT\", True)\n",
    "        self.NYT = self.root\n",
    "        self.free_index = 999\n",
    "        self.leaves = {}\n",
    "        self.node_weights = [set(), set()]\n",
    "        self.leaf_weights = [set(), set()]\n",
    "\n",
    "    def get_leaf_code(self, node):\n",
    "        code = []\n",
    "        while node != self.root:\n",
    "            code.append(\"0\" if node == node.parent.left else \"1\")\n",
    "            node = node.parent\n",
    "        return \"\".join(code)[::-1]\n",
    "\n",
    "    def add_new_node(self, char):\n",
    "        right_child = AdaptiveNode(self.free_index, 1, char, True)\n",
    "        self.free_index -= 1\n",
    "        left_child = AdaptiveNode(self.free_index, 0, \"NYT\", True)\n",
    "        self.free_index -= 1\n",
    "\n",
    "        internal, self.NYT = self.NYT, left_child\n",
    "\n",
    "        internal.weight = 1\n",
    "        internal.character = \"\"\n",
    "        internal.external = False\n",
    "        internal.left = left_child\n",
    "        internal.right = right_child\n",
    "\n",
    "        right_child.parent = internal\n",
    "        left_child.parent = internal\n",
    "\n",
    "        self.leaves[char] = right_child\n",
    "        self.node_weights[1].add(right_child)\n",
    "        if internal != self.root:\n",
    "            self.node_weights[1].add(internal)\n",
    "\n",
    "        self.leaf_weights[1].add(right_child)\n",
    "        self.update(internal)\n",
    "\n",
    "    def update(self, node):\n",
    "        while node != self.root:\n",
    "            if node.parent.left == self.NYT:\n",
    "                change = max(self.leaf_weights[node.weight], key=lambda item: item.index)\n",
    "                interchange(node, change)\n",
    "            else:\n",
    "                change = max(self.node_weights[node.weight], key=lambda item: item.index)\n",
    "                interchange(node, change)\n",
    "\n",
    "            if node.external:\n",
    "                update_weight(node, self.leaf_weights)\n",
    "            update_weight(node, self.node_weights)\n",
    "            node.weight += 1\n",
    "            node = node.parent\n",
    "\n",
    "        self.root.weight += 1\n",
    "\n",
    "    def encode_text(self, text):\n",
    "        encoded = []\n",
    "        for c in text:\n",
    "            if c not in self.leaves:\n",
    "                encoded.append(self.get_leaf_code(self.NYT))\n",
    "                encoded.append(int_to_string(ord(c), 16))\n",
    "                self.add_new_node(c)\n",
    "            else:\n",
    "                encoded.append(self.get_leaf_code(self.leaves[c]))\n",
    "                self.update(self.leaves[c])\n",
    "\n",
    "        return add_last_bits(\"\".join(encoded))\n",
    "\n",
    "\n",
    "    def decode_text(self, text):\n",
    "        decoded = []\n",
    "        ind = 0\n",
    "        while ind < len(text):\n",
    "            ptr = self.root\n",
    "            while not ptr.external:\n",
    "                ptr = ptr.left if text[ind] == '0' else ptr.right\n",
    "                ind += 1\n",
    "\n",
    "            if ptr == self.NYT:\n",
    "                new_char = chr(string_to_int(text[ind:ind+16]))\n",
    "                decoded.append(new_char)\n",
    "                self.add_new_node(new_char)\n",
    "                ind += 16\n",
    "            else:\n",
    "                decoded.append(ptr.character)\n",
    "                self.update(ptr)\n",
    "        return \"\".join(decoded)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Współczynniki kompresji i testy czasowe"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "outputs": [],
   "source": [
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "from os.path import getsize\n",
    "\n",
    "files1 = [\"Gutenberg_files/\" + f for f in listdir(\"Gutenberg_files\") if isfile(join(\"Gutenberg_files\", f))]\n",
    "files2 = [\"random_files/\" + f for f in listdir(\"random_files\") if isfile(join(\"random_files\", f))]\n",
    "files3 = [\"Linux_kernel/\" + f for f in listdir(\"Linux_kernel\") if isfile(join(\"Linux_kernel\", f))]\n",
    "files = files1 + files2 + files3"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------\n",
      "Plik: Gutenberg_files/book.txt o rozmiarze 584 bajtów\n",
      "Statyczny Huffman\n",
      "Czas kompresji 0.00\n",
      "Czas dekompresji 0.00\n",
      "Sprawdzenie poprawności kompresji i dekompresji: True\n",
      "Współczynnik kompresji = 0.4486301369863014\n",
      "\n",
      "\n",
      "Dynamiczny Huffman\n",
      "Czas kompresji 0.01\n",
      "Czas dekompresji 0.00\n",
      "Sprawdzenie poprawności kompresji i dekompresji: True\n",
      "Współczynnik kompresji = 0.2996575342465754\n",
      "\n",
      "\n",
      "\n",
      "----------------\n",
      "Plik: Gutenberg_files/mickiewicz.txt o rozmiarze 14404 bajtów\n",
      "Statyczny Huffman\n",
      "Czas kompresji 0.00\n",
      "Czas dekompresji 0.01\n",
      "Sprawdzenie poprawności kompresji i dekompresji: True\n",
      "Współczynnik kompresji = 0.4321021938350458\n",
      "\n",
      "\n",
      "Dynamiczny Huffman\n",
      "Czas kompresji 0.13\n",
      "Czas dekompresji 0.10\n",
      "Sprawdzenie poprawności kompresji i dekompresji: True\n",
      "Współczynnik kompresji = 0.4159261316301027\n",
      "\n",
      "\n",
      "\n",
      "----------------\n",
      "Plik: Gutenberg_files/moby_dick.txt o rozmiarze 1276229 bajtów\n",
      "Statyczny Huffman\n",
      "Czas kompresji 0.62\n",
      "Czas dekompresji 0.77\n",
      "Sprawdzenie poprawności kompresji i dekompresji: True\n",
      "Współczynnik kompresji = 0.45097157328347814\n",
      "\n",
      "\n",
      "Dynamiczny Huffman\n",
      "Czas kompresji 12.20\n",
      "Czas dekompresji 11.52\n",
      "Sprawdzenie poprawności kompresji i dekompresji: True\n",
      "Współczynnik kompresji = 0.45076393029777573\n",
      "\n",
      "\n",
      "\n",
      "----------------\n",
      "Plik: Gutenberg_files/tom_sawyer.txt o rozmiarze 147643 bajtów\n",
      "Statyczny Huffman\n",
      "Czas kompresji 0.03\n",
      "Czas dekompresji 0.09\n",
      "Sprawdzenie poprawności kompresji i dekompresji: True\n",
      "Współczynnik kompresji = 0.4489613459493508\n",
      "\n",
      "\n",
      "Dynamiczny Huffman\n",
      "Czas kompresji 2.13\n",
      "Czas dekompresji 1.13\n",
      "Sprawdzenie poprawności kompresji i dekompresji: True\n",
      "Współczynnik kompresji = 0.4475322229973653\n",
      "\n",
      "\n",
      "\n",
      "----------------\n",
      "Plik: random_files/file_size_1000kb.txt o rozmiarze 1008461 bajtów\n",
      "Statyczny Huffman\n",
      "Czas kompresji 0.22\n",
      "Czas dekompresji 0.83\n",
      "Sprawdzenie poprawności kompresji i dekompresji: True\n",
      "Współczynnik kompresji = 0.14286521739561564\n",
      "\n",
      "\n",
      "Dynamiczny Huffman\n",
      "Czas kompresji 11.18\n",
      "Czas dekompresji 13.59\n",
      "Sprawdzenie poprawności kompresji i dekompresji: True\n",
      "Współczynnik kompresji = 0.1414154835933169\n",
      "\n",
      "\n",
      "\n",
      "----------------\n",
      "Plik: random_files/file_size_100kb.txt o rozmiarze 100854 bajtów\n",
      "Statyczny Huffman\n",
      "Czas kompresji 0.02\n",
      "Czas dekompresji 0.08\n",
      "Sprawdzenie poprawności kompresji i dekompresji: True\n",
      "Współczynnik kompresji = 0.14332599599420948\n",
      "\n",
      "\n",
      "Dynamiczny Huffman\n",
      "Czas kompresji 1.18\n",
      "Czas dekompresji 1.50\n",
      "Sprawdzenie poprawności kompresji i dekompresji: True\n",
      "Współczynnik kompresji = 0.13930037479921475\n",
      "\n",
      "\n",
      "\n",
      "----------------\n",
      "Plik: random_files/file_size_10kb.txt o rozmiarze 10076 bajtów\n",
      "Statyczny Huffman\n",
      "Czas kompresji 0.00\n",
      "Czas dekompresji 0.01\n",
      "Sprawdzenie poprawności kompresji i dekompresji: True\n",
      "Współczynnik kompresji = 0.14311234616911472\n",
      "\n",
      "\n",
      "Dynamiczny Huffman\n",
      "Czas kompresji 0.12\n",
      "Czas dekompresji 0.11\n",
      "Sprawdzenie poprawności kompresji i dekompresji: True\n",
      "Współczynnik kompresji = 0.11581976974990071\n",
      "\n",
      "\n",
      "\n",
      "----------------\n",
      "Plik: random_files/file_size_1kb.txt o rozmiarze 3037 bajtów\n",
      "Statyczny Huffman\n",
      "Czas kompresji 0.00\n",
      "Czas dekompresji 0.00\n",
      "Sprawdzenie poprawności kompresji i dekompresji: True\n",
      "Współczynnik kompresji = 0.1550872571616727\n",
      "\n",
      "\n",
      "Dynamiczny Huffman\n",
      "Czas kompresji 0.03\n",
      "Czas dekompresji 0.04\n",
      "Sprawdzenie poprawności kompresji i dekompresji: True\n",
      "Współczynnik kompresji = 0.06947645702996375\n",
      "\n",
      "\n",
      "\n",
      "----------------\n",
      "Plik: Linux_kernel/makefile.txt o rozmiarze 735 bajtów\n",
      "Statyczny Huffman\n",
      "Czas kompresji 0.00\n",
      "Czas dekompresji 0.00\n",
      "Sprawdzenie poprawności kompresji i dekompresji: True\n",
      "Współczynnik kompresji = 0.3346938775510204\n",
      "\n",
      "\n",
      "Dynamiczny Huffman\n",
      "Czas kompresji 0.01\n",
      "Czas dekompresji 0.01\n",
      "Sprawdzenie poprawności kompresji i dekompresji: True\n",
      "Współczynnik kompresji = 0.1428571428571429\n",
      "\n",
      "\n",
      "\n",
      "----------------\n",
      "Plik: Linux_kernel/merged.txt o rozmiarze 1125007 bajtów\n",
      "Statyczny Huffman\n",
      "Czas kompresji 0.31\n",
      "Czas dekompresji 0.76\n",
      "Sprawdzenie poprawności kompresji i dekompresji: True\n",
      "Współczynnik kompresji = 0.36241196721442626\n",
      "\n",
      "\n",
      "Dynamiczny Huffman\n",
      "Czas kompresji 11.43\n",
      "Czas dekompresji 11.51\n",
      "Sprawdzenie poprawności kompresji i dekompresji: True\n",
      "Współczynnik kompresji = 0.3621897463749114\n",
      "\n",
      "\n",
      "\n",
      "----------------\n",
      "Plik: Linux_kernel/smpboot.txt o rozmiarze 12659 bajtów\n",
      "Statyczny Huffman\n",
      "Czas kompresji 0.00\n",
      "Czas dekompresji 0.01\n",
      "Sprawdzenie poprawności kompresji i dekompresji: True\n",
      "Współczynnik kompresji = 0.37625404850304134\n",
      "\n",
      "\n",
      "Dynamiczny Huffman\n",
      "Czas kompresji 0.09\n",
      "Czas dekompresji 0.09\n",
      "Sprawdzenie poprawności kompresji i dekompresji: True\n",
      "Współczynnik kompresji = 0.361955920688838\n",
      "\n",
      "\n",
      "\n",
      "----------------\n",
      "Plik: Linux_kernel/workqueue.txt o rozmiarze 129989 bajtów\n",
      "Statyczny Huffman\n",
      "Czas kompresji 0.03\n",
      "Czas dekompresji 0.07\n",
      "Sprawdzenie poprawności kompresji i dekompresji: True\n",
      "Współczynnik kompresji = 0.3734239050996623\n",
      "\n",
      "\n",
      "Dynamiczny Huffman\n",
      "Czas kompresji 1.08\n",
      "Czas dekompresji 1.63\n",
      "Sprawdzenie poprawności kompresji i dekompresji: True\n",
      "Współczynnik kompresji = 0.37162375277908133\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for file in files:\n",
    "    static_tree = StaticHuffman()\n",
    "    adaptive_encoder = AdaptiveHuffman()\n",
    "    adaptive_decoder = AdaptiveHuffman()\n",
    "    print(\"----------------\")\n",
    "    print(f\"Plik: {file} o rozmiarze {getsize(file)} bajtów\")\n",
    "    f_content = read_file_to_string(file)\n",
    "    t = perf_counter()\n",
    "    compressed = static_tree.encode_text(f_content)\n",
    "    t = perf_counter() - t\n",
    "    print(\"Statyczny Huffman\")\n",
    "    print(f\"Czas kompresji {t:.2f}\")\n",
    "\n",
    "    write_string_to_binary_file(\"compressed.bin\", compressed)\n",
    "    to_decode = read_binary_file_to_string(\"compressed.bin\")\n",
    "    t = perf_counter()\n",
    "    decompressed = static_tree.decode_text(to_decode)\n",
    "    t = perf_counter() - t\n",
    "    print(f\"Czas dekompresji {t:.2f}\")\n",
    "    print(f\"Sprawdzenie poprawności kompresji i dekompresji: {decompressed == f_content}\")\n",
    "    print(f\"Współczynnik kompresji = {1 - (getsize('compressed.bin') / getsize(file))}\")\n",
    "\n",
    "    print()\n",
    "    print()\n",
    "\n",
    "    t = perf_counter()\n",
    "    compressed = adaptive_encoder.encode_text(f_content)\n",
    "    t = perf_counter() - t\n",
    "    print(\"Dynamiczny Huffman\")\n",
    "    print(f\"Czas kompresji {t:.2f}\")\n",
    "\n",
    "    write_string_to_binary_file(\"compressed.bin\", compressed)\n",
    "    to_decode = read_binary_file_to_string(\"compressed.bin\")\n",
    "\n",
    "    t = perf_counter()\n",
    "    decompressed = adaptive_decoder.decode_text(to_decode)\n",
    "    t = perf_counter() - t\n",
    "    print(f\"Czas dekompresji {t:.2f}\")\n",
    "    print(f\"Sprawdzenie poprawności kompresji i dekompresji: {decompressed == f_content}\")\n",
    "    print(f\"Współczynnik kompresji = {1 - (getsize('compressed.bin') / getsize(file))}\")\n",
    "    print(\"\\n\\n\")\n",
    "\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Algorytm o zmiennym bloku kompresji LZW (Lempel–Ziv–Welch)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "outputs": [],
   "source": [
    "content = read_file_to_string(\"test\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "outputs": [],
   "source": [
    "class TrieNode:\n",
    "    def __init__(self, prefix_id):\n",
    "        self.id = prefix_id\n",
    "        self.edges = {}"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "outputs": [],
   "source": [
    "def encoding(text):\n",
    "    encoded = []\n",
    "    root = TrieNode(0)\n",
    "    for i in range(1, 256):\n",
    "        root.edges[chr(i)] = TrieNode(i)\n",
    "    last = 256\n",
    "    ptr = root\n",
    "    for x in text:\n",
    "        if x not in ptr.edges:\n",
    "            encoded.append(ptr.id)\n",
    "            ptr.edges[x] = TrieNode(last)\n",
    "            last += 1\n",
    "            ptr = root\n",
    "        else:\n",
    "            ptr = ptr.edges[x]\n",
    "\n",
    "    if ptr != root:\n",
    "        encoded.append(ptr.id)\n",
    "    return encoded\n",
    "\n",
    "\n",
    "def decoding(text):\n",
    "    decode = []\n",
    "    words = {}\n",
    "    for i in range(1, 256):\n",
    "        words[chr(i)] = chr(i)\n",
    "    words[\"\"] = \"\"\n",
    "    last = 256\n",
    "    word = \"\"\n",
    "    for x in text:\n",
    "        if x not in words:\n",
    "            decode.append(x)\n",
    "            words[word + x] = last\n",
    "            last += 1\n",
    "            word = \"\"\n",
    "        else:\n",
    "            decode.append(words[x])\n",
    "            word = words[word] + words[x]\n",
    "        print(decode)\n",
    "        print(words['s'])\n",
    "\n",
    "\n",
    "    return \"\".join(decode)\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "161\n",
      "siajdasikdklakslanklsdnkasdk;fmak;sfmkmasd\n",
      "pasjasdjikansdnjladjslnajldjlnajlsdlnad\n",
      "iasdjklnasljkdlnaslkdnlajkdjsnaldsljnad\n",
      "oasjdiasikdnmaiksdklnaksldnkladslnasdn\n",
      "66\n",
      "[115, 97, 100, 256, 100, 108, 107, 261, 107, 115, 110, 97, 260, 102, 97, 59, 269, 109, 265, 112, 115, 267, 106, 107, 110, 100, 106, 97, 106, 108, 257, 100, 285, 282, 100, 110, 100, 105, 265, 264, 267, 106, 290, 296, 281, 257, 287, 291, 100, 108, 291, 10, 267, 100, 267, 107, 110, 97, 262, 295, 262, 281, 261, 115, 291, 281]\n"
     ]
    }
   ],
   "source": [
    "print(len(content))\n",
    "print(content)\n",
    "coded = encoding(content)\n",
    "print(len(coded))\n",
    "print(coded)\n",
    "# decoded = decoding(coded)\n",
    "\n",
    "# print(decoded)\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
